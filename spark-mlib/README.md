# Spark MLlib: Proyecto de Machine Learning con PySpark

## Descripci√≥n

Este repositorio contiene un conjunto completo de notebooks de Jupyter que demuestran el uso de **Apache Spark MLlib** para tareas de Machine Learning. El proyecto cubre desde el preprocesamiento de datos hasta la implementaci√≥n de algoritmos de aprendizaje supervisado y no supervisado.

**Autor**: Omar Gaston - oy-gastonc@javeriana.edu.co

## Contenido

### 1. Preprocesamiento de Datos (`ML_Preprocesamiento_Omar.ipynb`)

Este notebook muestra t√©cnicas esenciales de limpieza y transformaci√≥n de datos usando el dataset del Titanic:

- **Identificaci√≥n y relleno de valores faltantes**
- **Eliminaci√≥n de duplicados**
- **Eliminaci√≥n de columnas que no aportan valor**
- **Operaciones Pivot y Explode**
- **Normalizaci√≥n de datos** (StandardScaler y MinMaxScaler)

**Dataset**: `titanic.csv` (891 pasajeros del Titanic)

### 2. Aprendizaje Supervisado (`ML_Supervisado_Omar.ipynb`)

Implementaci√≥n y comparaci√≥n de modelos de clasificaci√≥n para predecir la calidad del vino:

- **Preparaci√≥n de features** (VectorAssembler, normalizaci√≥n)
- **Divisi√≥n Train/Test**
- **Regresi√≥n Log√≠stica**
- **Random Forest Classifier**
- **Evaluaci√≥n y comparaci√≥n de modelos** (matriz de confusi√≥n, m√©tricas de precisi√≥n)

**Dataset**: `winequality-red.csv` (1,599 muestras de vino tinto de Portugal)

**Problema**: Clasificaci√≥n binaria (calidad buena ‚â• 6 vs. calidad mala < 6)

### 3. Aprendizaje No Supervisado (`ML_NoSupervisado_Omar.ipynb`)

An√°lisis de clustering para descubrir grupos naturales en los datos de vinos:

- **Preparaci√≥n de features** (normalizaci√≥n)
- **K-Means Clustering**
- **Bisecting K-Means Clustering**
- **Evaluaci√≥n de clusters** (Silhouette Score, visualizaci√≥n)

**Dataset**: `winequality-red.csv` (1,599 muestras de vino tinto)

**Objetivo**: Descubrir patrones y grupos naturales basados en propiedades qu√≠micas

## Datasets

### Titanic Dataset (`titanic.csv`)
- **Filas**: 891 pasajeros
- **Columnas**: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked
- **Caracter√≠sticas**: Valores faltantes (~20% en Age, ~77% en Cabin), duplicados, columnas inconsistentes

### Wine Quality Dataset (`winequality-red.csv`)
- **Filas**: 1,599 muestras
- **Columnas**: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol, quality
- **Caracter√≠sticas**: Dataset limpio con propiedades qu√≠micas medibles del vino

## üõ†Ô∏è Tecnolog√≠as y Librer√≠as

### Core
- **Apache Spark** (PySpark)
- **Spark MLlib** (Machine Learning library)

### Python Libraries
- `findspark` - Inicializaci√≥n de Spark
- `pandas` - Manipulaci√≥n de datos
- `numpy` - Operaciones num√©ricas
- `matplotlib` - Visualizaci√≥n
- `seaborn` - Visualizaci√≥n estad√≠stica

### Spark MLlib Components
- `VectorAssembler` - Creaci√≥n de vectores de caracter√≠sticas
- `StandardScaler` - Estandarizaci√≥n (media=0, std=1)
- `MinMaxScaler` - Normalizaci√≥n (rango [0, 1])
- `LogisticRegression` - Regresi√≥n log√≠stica
- `RandomForestClassifier` - Clasificador de bosque aleatorio
- `KMeans` - Clustering K-Means
- `BisectingKMeans` - Clustering K-Means jer√°rquico
- `ClusteringEvaluator` - Evaluaci√≥n de clusters

## Configuraci√≥n

### Requisitos Previos
- Python 3.11+
- Apache Spark instalado y configurado
- Jupyter Notebook o JupyterLab

### Instalaci√≥n

```bash
# Instalar dependencias
pip install findspark pandas numpy matplotlib seaborn

# Asegurarse de que Spark est√© correctamente configurado
# Configurar variables de entorno si es necesario:
# export SPARK_HOME=/path/to/spark
# export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH
```

### Configuraci√≥n de Spark

Los notebooks utilizan configuraciones optimizadas de Spark:

```python
sparkConf = (
    SparkConf()
        .set("spark.scheduler.mode", "FAIR")
        .set("spark.shuffle.io.maxRetries", "10")
        # ... m√°s configuraciones
)
```

## Estructura de los Notebooks

Cada notebook sigue una estructura similar:

1. **Contexto del Problema** - Descripci√≥n del dataset y objetivos
2. **Inicializaci√≥n de Spark** - Configuraci√≥n de la sesi√≥n
3. **Carga y Exploraci√≥n de Datos** - An√°lisis exploratorio inicial
4. **Preparaci√≥n de Features** - Ingenier√≠a de caracter√≠sticas
5. **Entrenamiento de Modelos** - Implementaci√≥n de algoritmos
6. **Evaluaci√≥n** - M√©tricas y comparaci√≥n de modelos
7. **Resumen y Conclusiones** - Insights y resultados finales

## Resultados Clave

### Preprocesamiento
- Identificaci√≥n y manejo de valores faltantes
- Eliminaci√≥n de duplicados y columnas innecesarias
- Transformaciones con Pivot y Explode
- Normalizaci√≥n de datos para ML

### Aprendizaje Supervisado
- Comparaci√≥n entre Regresi√≥n Log√≠stica y Random Forest
- Evaluaci√≥n mediante matriz de confusi√≥n y m√©tricas de precisi√≥n
- Identificaci√≥n del mejor modelo para clasificaci√≥n de calidad de vino

### Aprendizaje No Supervisado
- Descubrimiento de grupos naturales en los datos
- Comparaci√≥n entre K-Means y Bisecting K-Means
- Evaluaci√≥n mediante Silhouette Score y visualizaci√≥n

## Documentaci√≥n Adicional

- `Evaluaciones de PySpark.pdf` - Documentaci√≥n adicional sobre evaluaciones de PySpark

## Autor

**Omar Gaston**
- Email: oy-gastonc@javeriana.edu.co
- Universidad: Pontificia Universidad Javeriana (PUJ)

## Notas

- Los notebooks est√°n dise√±ados para ejecutarse en entornos con al menos **4 cores** y **4GB de memoria** para un rendimiento √≥ptimo
- Se recomienda revisar la configuraci√≥n de Spark seg√∫n los recursos disponibles
- Los datasets est√°n incluidos en el repositorio para facilitar la reproducci√≥n de los experimentos

## Referencias

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Spark MLlib Guide](https://spark.apache.org/docs/latest/ml-guide.html)
- [PySpark API Reference](https://spark.apache.org/docs/latest/api/python/)

